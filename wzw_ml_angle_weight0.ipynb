{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [21]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025054,
     "end_time": "2020-08-30T01:18:39.204256",
     "exception": false,
     "start_time": "2020-08-30T01:18:39.179202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine Learning for String Field Theory\n",
    "\n",
    "*H. Erbin, R. Finotello, M. Kudrna, M. Schnabl*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "In the framework of bosonic **Open String Field Theory** (OSFT), we consider several observables characterised by conformal weight, periodicity of the oscillations and the position of vacua in the potential for various values of truncated mass level.\n",
    "We focus on the prediction of the extrapolated value for the level-$\\infty$ truncation using Machine Learning (ML) techniques.\n",
    "\n",
    "## Synopsis\n",
    "\n",
    "In this notebook we train the machine learning algorithms on the WZW dataset.\n",
    "We focus on computing the argument angle of the extrapolated label and weight $h = 0$.\n",
    "\n",
    "## General Observations\n",
    "\n",
    "The idea is to improve the finite level predictions and reaching a result as close as possible to the extrapolated label.\n",
    "We need to find a strategy to evaluate the extrapolated labels with respect to the finite level truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:39.256957Z",
     "iopub.status.busy": "2020-08-30T01:18:39.256045Z",
     "iopub.status.idle": "2020-08-30T01:18:40.351087Z",
     "shell.execute_reply": "2020-08-30T01:18:40.350564Z"
    },
    "papermill": {
     "duration": 1.127043,
     "end_time": "2020-08-30T01:18:40.351201",
     "exception": false,
     "start_time": "2020-08-30T01:18:39.224158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from tensorflow import keras\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from analysis import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n",
    "\n",
    "# set matplot\n",
    "sns.set()\n",
    "PREFIX = 'wzw_'\n",
    "SUFFIX = '_angle_w0'\n",
    "\n",
    "# set memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "# set random seed\n",
    "RAND = 123\n",
    "np.random.seed(RAND)\n",
    "tf.random.set_seed(RAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:40.397588Z",
     "iopub.status.busy": "2020-08-30T01:18:40.397340Z",
     "iopub.status.idle": "2020-08-30T01:18:40.412443Z",
     "shell.execute_reply": "2020-08-30T01:18:40.412049Z"
    },
    "papermill": {
     "duration": 0.036665,
     "end_time": "2020-08-30T01:18:40.412545",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.375880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create shortcuts for paths\n",
    "proot = lambda s: os.path.join('.', s)\n",
    "pdata = lambda s: os.path.join(proot('data'), s)\n",
    "pimg  = lambda s: os.path.join(proot('img'), s)\n",
    "pmet  = lambda s: os.path.join(proot('metrics'), s)\n",
    "pmod  = lambda s: os.path.join(proot('models'), s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019584,
     "end_time": "2020-08-30T01:18:40.455917",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.436333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:40.496687Z",
     "iopub.status.busy": "2020-08-30T01:18:40.496434Z",
     "iopub.status.idle": "2020-08-30T01:18:40.525376Z",
     "shell.execute_reply": "2020-08-30T01:18:40.524986Z"
    },
    "papermill": {
     "duration": 0.050051,
     "end_time": "2020-08-30T01:18:40.525477",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.475426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41 entries, 0 to 558\n",
      "Data columns (total 38 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   k            41 non-null     float64\n",
      " 1   weight       41 non-null     float64\n",
      " 2   j            41 non-null     float64\n",
      " 3   m            41 non-null     float64\n",
      " 4   type_2       41 non-null     int64  \n",
      " 5   type_4       41 non-null     int64  \n",
      " 6   level_2      41 non-null     object \n",
      " 7   level_3      41 non-null     object \n",
      " 8   level_4      41 non-null     object \n",
      " 9   level_5      41 non-null     object \n",
      " 10  level_6      41 non-null     object \n",
      " 11  level_7      41 non-null     object \n",
      " 12  level_8      41 non-null     object \n",
      " 13  level_9      41 non-null     object \n",
      " 14  level_10     41 non-null     object \n",
      " 15  level_2_re   41 non-null     float64\n",
      " 16  level_3_re   41 non-null     float64\n",
      " 17  level_4_re   41 non-null     float64\n",
      " 18  level_5_re   41 non-null     float64\n",
      " 19  level_6_re   41 non-null     float64\n",
      " 20  level_7_re   41 non-null     float64\n",
      " 21  level_8_re   41 non-null     float64\n",
      " 22  level_9_re   41 non-null     float64\n",
      " 23  level_10_re  41 non-null     float64\n",
      " 24  level_2_im   41 non-null     float64\n",
      " 25  level_3_im   41 non-null     float64\n",
      " 26  level_4_im   41 non-null     float64\n",
      " 27  level_5_im   41 non-null     float64\n",
      " 28  level_6_im   41 non-null     float64\n",
      " 29  level_7_im   41 non-null     float64\n",
      " 30  level_8_im   41 non-null     float64\n",
      " 31  level_9_im   41 non-null     float64\n",
      " 32  level_10_im  41 non-null     float64\n",
      " 33  exp          41 non-null     object \n",
      " 34  exp_re       41 non-null     float64\n",
      " 35  exp_im       41 non-null     float64\n",
      " 36  exp_angle    41 non-null     float64\n",
      " 37  exp_mod      41 non-null     float64\n",
      "dtypes: float64(26), int64(2), object(10)\n",
      "memory usage: 12.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(pdata('wzw.csv'))\n",
    "df = df.loc[df['weight'] == 0.0]\n",
    "last = 'level_10'\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:40.570763Z",
     "iopub.status.busy": "2020-08-30T01:18:40.570521Z",
     "iopub.status.idle": "2020-08-30T01:18:40.589131Z",
     "shell.execute_reply": "2020-08-30T01:18:40.588740Z"
    },
    "papermill": {
     "duration": 0.040072,
     "end_time": "2020-08-30T01:18:40.589232",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.549160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert strings to complex numbers\n",
    "columns = df.loc[:,df.dtypes == 'object'].columns\n",
    "for c in columns:\n",
    "    df[c] = df[c].astype(np.complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019553,
     "end_time": "2020-08-30T01:18:40.632387",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.612834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to:\n",
    "\n",
    "1. define the evaluation metrics,\n",
    "2. rescale the labels,\n",
    "3. define the cross-validation strategy,\n",
    "4. divide into training and test sets,\n",
    "5. train the algorithms,\n",
    "6. evaluate each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019748,
     "end_time": "2020-08-30T01:18:40.671872",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.652124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation Metric\n",
    "\n",
    "In general we use the average ratio between the residuals of predicted level and the last finite truncation level:\n",
    "\\begin{equation}\n",
    "    R(y_{true}, y_{finite}, y_{pred}) = \\frac{1}{N} \\sum\\limits_{i = 1}^N \\log_{10}\\left| \\frac{y_{true}^{(i)} - y_{pred}^{(i)}}{y_{true}^{(i)} - y_{finite}^{(i)}} \\right|\n",
    "\\end{equation}\n",
    "This way a negative result would represent an improvement on finite truncation levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019812,
     "end_time": "2020-08-30T01:18:40.711435",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.691623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross-Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:40.752908Z",
     "iopub.status.busy": "2020-08-30T01:18:40.752663Z",
     "iopub.status.idle": "2020-08-30T01:18:40.768438Z",
     "shell.execute_reply": "2020-08-30T01:18:40.768047Z"
    },
    "papermill": {
     "duration": 0.03721,
     "end_time": "2020-08-30T01:18:40.768539",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.731329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01984,
     "end_time": "2020-08-30T01:18:40.812427",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.792587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:40.855518Z",
     "iopub.status.busy": "2020-08-30T01:18:40.855221Z",
     "iopub.status.idle": "2020-08-30T01:18:40.875390Z",
     "shell.execute_reply": "2020-08-30T01:18:40.874997Z"
    },
    "papermill": {
     "duration": 0.043249,
     "end_time": "2020-08-30T01:18:40.875490",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.832241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size=0.9, shuffle=True, random_state=RAND)\n",
    "\n",
    "X_train = train.filter(regex='k|weight|type_.*|level_[0-9]*$')\n",
    "X_train.to_csv(pdata(PREFIX + 'X_train' + SUFFIX + '.csv'), index=False)\n",
    "X_train = X_train.drop(columns=['k']).values\n",
    "\n",
    "X_test  = test.filter(regex='k|weight|type_.*|level_[0-9]*$')\n",
    "X_test.to_csv(pdata(PREFIX + 'X_test' + SUFFIX + '.csv'), index=False)\n",
    "X_test = X_test.drop(columns=['k']).values\n",
    "\n",
    "y_train = train['exp_angle']\n",
    "y_train.to_csv(pdata(PREFIX + 'y_train' + SUFFIX + '.csv'), index=False)\n",
    "y_train = y_train.values.reshape(-1,)\n",
    "\n",
    "y_test  = test['exp_angle']\n",
    "y_test.to_csv(pdata(PREFIX + 'y_test' + SUFFIX + '.csv'), index=False)\n",
    "y_test = y_test.values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:40.921955Z",
     "iopub.status.busy": "2020-08-30T01:18:40.921701Z",
     "iopub.status.idle": "2020-08-30T01:18:40.937367Z",
     "shell.execute_reply": "2020-08-30T01:18:40.936935Z"
    },
    "papermill": {
     "duration": 0.037432,
     "end_time": "2020-08-30T01:18:40.937467",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.900035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: X = (36, 12), y = (36,)\n",
      "Shape of the test     set: X = (5, 12),  y = (5,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the training set: X = {X_train.shape}, y = {y_train.shape}')\n",
    "print(f'Shape of the test     set: X = {X_test.shape},  y = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019912,
     "end_time": "2020-08-30T01:18:40.983063",
     "exception": false,
     "start_time": "2020-08-30T01:18:40.963151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also need a validation set (10% of the samples) for the neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.032706Z",
     "iopub.status.busy": "2020-08-30T01:18:41.027983Z",
     "iopub.status.idle": "2020-08-30T01:18:41.055173Z",
     "shell.execute_reply": "2020-08-30T01:18:41.054931Z"
    },
    "papermill": {
     "duration": 0.052181,
     "end_time": "2020-08-30T01:18:41.055237",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.003056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, validation = train_test_split(train, test_size=1/9, shuffle=True, random_state=RAND)\n",
    "\n",
    "X_train_nn = train.filter(regex='k|weight|type_.*|level_[0-9]*$')\n",
    "X_train_nn.to_csv(pdata(PREFIX + 'X_train_nn' + SUFFIX + '.csv'), index=False)\n",
    "X_train_nn = X_train_nn.drop(columns=['k']).values\n",
    "\n",
    "X_val_nn  = validation.filter(regex='k|weight|type_.*|level_[0-9]*$')\n",
    "X_val_nn.to_csv(pdata(PREFIX + 'X_val_nn' + SUFFIX + '.csv'), index=False)\n",
    "X_val_nn = X_val_nn.drop(columns=['k']).values\n",
    "\n",
    "y_train_nn = train['exp_angle']\n",
    "y_train_nn.to_csv(pdata(PREFIX + 'y_train_nn' + SUFFIX + '.csv'), index=False)\n",
    "y_train_nn = y_train_nn.values.reshape(-1,)\n",
    "\n",
    "y_val_nn  = validation['exp_angle']\n",
    "y_val_nn.to_csv(pdata(PREFIX + 'y_val_nn' + SUFFIX + '.csv'), index=False)\n",
    "y_val_nn = y_val_nn.values.reshape(-1,)\n",
    "\n",
    "y_test_nn = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.099527Z",
     "iopub.status.busy": "2020-08-30T01:18:41.099144Z",
     "iopub.status.idle": "2020-08-30T01:18:41.117021Z",
     "shell.execute_reply": "2020-08-30T01:18:41.116761Z"
    },
    "papermill": {
     "duration": 0.039475,
     "end_time": "2020-08-30T01:18:41.117081",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.077606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training   set (ANN): X = (32, 12), y = (32,)\n",
      "Shape of the validation set (ANN): X = (4, 12),  y = (4,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the training   set (ANN): X = {X_train_nn.shape}, y = {y_train_nn.shape}')\n",
    "print(f'Shape of the validation set (ANN): X = {X_val_nn.shape},  y = {y_val_nn.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020022,
     "end_time": "2020-08-30T01:18:41.157319",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.137297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Extract the Last Truncation Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.200522Z",
     "iopub.status.busy": "2020-08-30T01:18:41.200134Z",
     "iopub.status.idle": "2020-08-30T01:18:41.216229Z",
     "shell.execute_reply": "2020-08-30T01:18:41.215989Z"
    },
    "papermill": {
     "duration": 0.038883,
     "end_time": "2020-08-30T01:18:41.216292",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.177409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_train    = np.angle(X_train[:,-1]).reshape(-1,) / np.pi\n",
    "last_train_nn = np.angle(X_train_nn[:,-1]).reshape(-1,) / np.pi\n",
    "last_val_nn   = np.angle(X_val_nn[:,-1]).reshape(-1,) / np.pi\n",
    "last_test     = np.angle(X_test[:,-1]).reshape(-1,) / np.pi\n",
    "last_test_nn  = np.angle(X_test[:,-1]).reshape(-1,) / np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020284,
     "end_time": "2020-08-30T01:18:41.256785",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.236501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Apply Fourier Transform to Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.301684Z",
     "iopub.status.busy": "2020-08-30T01:18:41.301284Z",
     "iopub.status.idle": "2020-08-30T01:18:41.319902Z",
     "shell.execute_reply": "2020-08-30T01:18:41.319665Z"
    },
    "papermill": {
     "duration": 0.042984,
     "end_time": "2020-08-30T01:18:41.319964",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.276980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute Fourier transform (for real input)\n",
    "levels_train    = np.fft.fft(X_train[:,3:], axis=1)\n",
    "levels_train_nn = np.fft.fft(X_train_nn[:,3:], axis=1)\n",
    "levels_val_nn   = np.fft.fft(X_val_nn[:,3:], axis=1)\n",
    "levels_test     = np.fft.fft(X_test[:,3:], axis=1)\n",
    "\n",
    "# separate modulus and argument\n",
    "levels_train_mod    = np.abs(levels_train)\n",
    "levels_train_ang    = np.angle(levels_train) / np.pi\n",
    "levels_train_nn_mod = np.abs(levels_train_nn)\n",
    "levels_train_nn_ang = np.angle(levels_train_nn) / np.pi\n",
    "levels_val_nn_mod   = np.abs(levels_val_nn)\n",
    "levels_val_nn_ang   = np.angle(levels_val_nn) / np.pi\n",
    "levels_test_mod     = np.abs(levels_test)\n",
    "levels_test_ang     = np.angle(levels_test) / np.pi\n",
    "\n",
    "# concatenate the arrays (the first imaginary part is identically vanishing)\n",
    "levels_train_conc    = np.c_[levels_train_mod[:,1:], levels_train_ang[:,1:]]\n",
    "levels_train_nn_conc = np.c_[levels_train_nn_mod[:,1:], levels_train_nn_ang[:,1:]]\n",
    "levels_val_nn_conc   = np.c_[levels_val_nn_mod[:,1:], levels_val_nn_ang[:,1:]]\n",
    "levels_test_conc     = np.c_[levels_test_mod[:,1:], levels_test_ang[:,1:]]\n",
    "\n",
    "# reform the input vectors\n",
    "X_train    = np.c_[np.real(X_train[:,0:3]), levels_train_conc]\n",
    "X_train_nn = np.c_[np.real(X_train_nn[:,0:3]), levels_train_nn_conc]\n",
    "X_val_nn   = np.c_[np.real(X_val_nn[:,0:3]), levels_val_nn_conc]\n",
    "X_test     = np.c_[np.real(X_test[:,0:3]), levels_test_conc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020014,
     "end_time": "2020-08-30T01:18:41.360140",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.340126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rescale the Truncation Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.403410Z",
     "iopub.status.busy": "2020-08-30T01:18:41.402808Z",
     "iopub.status.idle": "2020-08-30T01:18:41.419871Z",
     "shell.execute_reply": "2020-08-30T01:18:41.419635Z"
    },
    "papermill": {
     "duration": 0.039749,
     "end_time": "2020-08-30T01:18:41.419933",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.380184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lev_scaler    = StandardScaler()\n",
    "lev_scaler_nn = StandardScaler()\n",
    "\n",
    "# scale the cross-validation levels\n",
    "levels_train = lev_scaler.fit_transform(X_train[:,3:])\n",
    "levels_test  = lev_scaler.transform(X_test[:,3:])\n",
    "\n",
    "# scale the neural network labels\n",
    "levels_train_nn = lev_scaler_nn.fit_transform(X_train_nn[:,3:])\n",
    "levels_val_nn   = lev_scaler_nn.transform(X_val_nn[:,3:])\n",
    "levels_test_nn  = lev_scaler_nn.transform(X_test[:,3:])\n",
    "\n",
    "# insert the levels back\n",
    "X_train[:,3:] = levels_train\n",
    "X_test[:,3:]  = levels_test\n",
    "\n",
    "X_train_nn[:,3:] = levels_train_nn\n",
    "X_val_nn[:,3:]   = levels_val_nn\n",
    "X_test_nn        = X_test\n",
    "X_test_nn[:,3:]  = levels_test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.462475Z",
     "iopub.status.busy": "2020-08-30T01:18:41.461826Z",
     "iopub.status.idle": "2020-08-30T01:18:41.477839Z",
     "shell.execute_reply": "2020-08-30T01:18:41.477606Z"
    },
    "papermill": {
     "duration": 0.037714,
     "end_time": "2020-08-30T01:18:41.477900",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.440186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('./models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.520445Z",
     "iopub.status.busy": "2020-08-30T01:18:41.520062Z",
     "iopub.status.idle": "2020-08-30T01:18:41.537660Z",
     "shell.execute_reply": "2020-08-30T01:18:41.537391Z"
    },
    "papermill": {
     "duration": 0.039594,
     "end_time": "2020-08-30T01:18:41.537722",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.498128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/wzw_levels_nn_scaler_angle_w0.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the scalers\n",
    "joblib.dump(lev_scaler, pmod(PREFIX + 'levels_cv_scaler' + SUFFIX + '.pkl'))\n",
    "joblib.dump(lev_scaler_nn, pmod(PREFIX + 'levels_nn_scaler' + SUFFIX + '.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0201,
     "end_time": "2020-08-30T01:18:41.579779",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.559679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.622002Z",
     "iopub.status.busy": "2020-08-30T01:18:41.621616Z",
     "iopub.status.idle": "2020-08-30T01:18:41.639673Z",
     "shell.execute_reply": "2020-08-30T01:18:41.639440Z"
    },
    "papermill": {
     "duration": 0.039758,
     "end_time": "2020-08-30T01:18:41.639735",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.599977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('./img', exist_ok=True)\n",
    "os.makedirs('./metrics', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020106,
     "end_time": "2020-08-30T01:18:41.683032",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.662926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Linear Regression (w/ $\\ell_2$ regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:18:41.726355Z",
     "iopub.status.busy": "2020-08-30T01:18:41.725965Z",
     "iopub.status.idle": "2020-08-30T01:20:08.788561Z",
     "shell.execute_reply": "2020-08-30T01:20:08.788788Z"
    },
    "papermill": {
     "duration": 87.085651,
     "end_time": "2020-08-30T01:20:08.788862",
     "exception": false,
     "start_time": "2020-08-30T01:18:41.703211",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation time: 87.024 seconds.\n"
     ]
    }
   ],
   "source": [
    "spaces    = {'alpha':         Real(1.0e-8, 1.0e-1, prior='log-uniform'),\n",
    "             'fit_intercept': Integer(0, 1),\n",
    "             'normalize':     Integer(0, 1)\n",
    "            }\n",
    "estimator = BayesSearchCV(Ridge(tol=1.0e-5, random_state=RAND),\n",
    "                          spaces,\n",
    "                          n_iter=100,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          n_jobs=-1,\n",
    "                          cv=cv,\n",
    "                          random_state=RAND\n",
    "                         )         \n",
    "\n",
    "# fit the estimator\n",
    "t = time.time()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "t = time.time() - t\n",
    "print(f'Optimisation time: {t:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:20:08.851887Z",
     "iopub.status.busy": "2020-08-30T01:20:08.845479Z",
     "iopub.status.idle": "2020-08-30T01:20:08.863789Z",
     "shell.execute_reply": "2020-08-30T01:20:08.863564Z"
    },
    "papermill": {
     "duration": 0.053778,
     "end_time": "2020-08-30T01:20:08.863845",
     "exception": false,
     "start_time": "2020-08-30T01:20:08.810067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: -0.000 ± 0.000\n"
     ]
    }
   ],
   "source": [
    "best_estimator, cv_score, best_hyperparameters = statisticsCV(estimator, cv)\n",
    "print(f'CV score: {-cv_score[0]:.3f} ± {cv_score[1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:20:08.916056Z",
     "iopub.status.busy": "2020-08-30T01:20:08.911466Z",
     "iopub.status.idle": "2020-08-30T01:20:08.924856Z",
     "shell.execute_reply": "2020-08-30T01:20:08.925061Z"
    },
    "papermill": {
     "duration": 0.040132,
     "end_time": "2020-08-30T01:20:08.925125",
     "exception": false,
     "start_time": "2020-08-30T01:20:08.884993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/wzw_lr_angle_w0.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save best estimator\n",
    "joblib.dump(best_estimator, pmod(PREFIX + 'lr' + SUFFIX + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:20:08.973475Z",
     "iopub.status.busy": "2020-08-30T01:20:08.973223Z",
     "iopub.status.idle": "2020-08-30T01:20:08.991485Z",
     "shell.execute_reply": "2020-08-30T01:20:08.990987Z"
    },
    "papermill": {
     "duration": 0.041282,
     "end_time": "2020-08-30T01:20:08.991587",
     "exception": false,
     "start_time": "2020-08-30T01:20:08.950305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.010253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_intercept</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalize</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ridge\n",
       "alpha          0.010253\n",
       "fit_intercept  0.000000\n",
       "normalize      0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the hyperparameters\n",
    "best_hyperparameters.to_csv(pmet(PREFIX + 'lr_hyperparameters' + SUFFIX + '.csv'))\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:20:09.041289Z",
     "iopub.status.busy": "2020-08-30T01:20:09.041030Z",
     "iopub.status.idle": "2020-08-30T01:20:09.064422Z",
     "shell.execute_reply": "2020-08-30T01:20:09.063979Z"
    },
    "papermill": {
     "duration": 0.046787,
     "end_time": "2020-08-30T01:20:09.064523",
     "exception": false,
     "start_time": "2020-08-30T01:20:09.017736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/documents/ml-sft-trunc/ml-sft-trunc-model-dep/analysis.py:75: RuntimeWarning: divide by zero encountered in log10\n",
      "  log_ratio = np.log10(ratio)\n",
      "/home/riccardo/documents/ml-sft-trunc/ml-sft-trunc-model-dep/analysis.py:75: RuntimeWarning: divide by zero encountered in log10\n",
      "  log_ratio = np.log10(ratio)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_lr</th>\n",
       "      <th>test_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_squared_error</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual_ratio</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_lr  test_lr\n",
       "mean_squared_error        0.0      0.0\n",
       "mean_absolute_error       0.0      0.0\n",
       "r2_score                  1.0      1.0\n",
       "residual_ratio           -inf     -inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics = make_predictions(best_estimator, X_train, y_train, last_train, prefix=PREFIX, suffix=SUFFIX, name='train_lr')\n",
    "test_metrics  = make_predictions(best_estimator, X_test, y_test, last_test, prefix=PREFIX, suffix=SUFFIX, name='test_lr')\n",
    "\n",
    "# concatenate the prediction results\n",
    "metrics = pd.concat([train_metrics, test_metrics], axis=0).transpose()\n",
    "metrics.to_csv(pmet(PREFIX + 'lr_metrics' + SUFFIX + '.csv'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T01:20:09.116126Z",
     "iopub.status.busy": "2020-08-30T01:20:09.115780Z",
     "iopub.status.idle": "2020-08-30T01:20:09.708737Z",
     "shell.execute_reply": "2020-08-30T01:20:09.708199Z"
    },
    "papermill": {
     "duration": 0.617,
     "end_time": "2020-08-30T01:20:09.708880",
     "exception": true,
     "start_time": "2020-08-30T01:20:09.091880",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/documents/ml-sft-trunc/ml-sft-trunc-model-dep/analysis.py:219: RuntimeWarning: divide by zero encountered in log10\n",
      "  resid_ratio = np.log10(np.abs(np.divide(resid_pred, resid_fin)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/conda/envs/ml-sft-trunc/lib/python3.7/site-packages/seaborn/utils.py:376: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return q3 - q1\n",
      "/home/riccardo/conda/envs/ml-sft-trunc/lib/python3.7/site-packages/seaborn/distributions.py:35: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return int(np.ceil((a.max() - a.min()) / h))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ba16d1ca47bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSUFFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_lr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmake_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSUFFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_lr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcompare_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSUFFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/documents/ml-sft-trunc/ml-sft-trunc-model-dep/analysis.py\u001b[0m in \u001b[0;36mmake_plots\u001b[0;34m(estimator, X, y, y_finite, name, prefix, suffix, figsize)\u001b[0m\n\u001b[1;32m    248\u001b[0m     sns.distplot(resid_ratio,\n\u001b[1;32m    249\u001b[0m                  \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                  \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 )\n\u001b[1;32m    252\u001b[0m     hist_ratio.set(title='',\n",
      "\u001b[0;32m~/conda/envs/ml-sft-trunc/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mdistplot\u001b[0;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_freedman_diaconis_bins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mhist_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mhist_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"density\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/ml-sft-trunc/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36m_freedman_diaconis_bins\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plots(estimator, X_train, y_train, last_train, prefix=PREFIX, suffix=SUFFIX, name='train_lr')\n",
    "make_plots(estimator, X_test, y_test, last_test, prefix=PREFIX, suffix=SUFFIX, name='test_lr')\n",
    "compare_plots(estimator, X_train, y_train, last_train, X_test, y_test, last_test, legend=['training', 'test'], prefix=PREFIX, suffix=SUFFIX, name='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'lr_residual_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'lr_ratio_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'lr_residual_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'lr_ratio_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Support Vector Machine (w/ Gaussian kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spaces    = {'gamma':   Real(1.0e-4, 1.0e1, prior='log-uniform'),\n",
    "             'C':       Real(1.0e-8, 1.0e-1, prior='log-uniform'),\n",
    "             'epsilon': Real(1.0e-4, 1.0e-1, prior='log-uniform')\n",
    "            }\n",
    "estimator = BayesSearchCV(SVR(kernel='rbf', tol=1.0e-5),\n",
    "                          spaces,\n",
    "                          n_iter=100,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          n_jobs=-1,\n",
    "                          cv=cv,\n",
    "                          random_state=RAND\n",
    "                         )         \n",
    "\n",
    "# fit the estimator\n",
    "t = time.time()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "t = time.time() - t\n",
    "print(f'Optimisation time: {t:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_estimator, cv_score, best_hyperparameters = statisticsCV(estimator, cv)\n",
    "print(f'CV score: {-cv_score[0]:.3f} ± {cv_score[1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save best estimator\n",
    "joblib.dump(best_estimator, pmod(PREFIX + 'svr' + SUFFIX + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the hyperparameters\n",
    "best_hyperparameters.to_csv(pmet(PREFIX + 'svr_hyperparameters' + SUFFIX + '.csv'))\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_metrics = make_predictions(best_estimator, X_train, y_train, last_train, prefix=PREFIX, suffix=SUFFIX, name='train_svr')\n",
    "test_metrics  = make_predictions(best_estimator, X_test, y_test, last_test, prefix=PREFIX, suffix=SUFFIX, name='test_svr')\n",
    "\n",
    "# concatenate the prediction results\n",
    "metrics = pd.concat([train_metrics, test_metrics], axis=0).transpose()\n",
    "metrics.to_csv(pmet(PREFIX + 'svr_metrics' + SUFFIX + '.csv'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_plots(estimator, X_train, y_train, last_train, prefix=PREFIX, suffix=SUFFIX, name='train_svr')\n",
    "make_plots(estimator, X_test, y_test, last_test, prefix=PREFIX, suffix=SUFFIX, name='test_svr')\n",
    "compare_plots(estimator, X_train, y_train, last_train, X_test, y_test, last_test, legend=['training', 'test'], prefix=PREFIX, suffix=SUFFIX, name='svr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'svr_residual_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'svr_ratio_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'svr_residual_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'svr_ratio_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spaces    = {'num_leaves':       Integer(2, 100),\n",
    "             'max_depth':        Integer(2, 25),\n",
    "             'learning_rate':    Real(1e-5, 1e-1, prior='log-uniform'),\n",
    "             'n_estimators':     Integer(1e1, 2e3, prior='log-uniform'),\n",
    "             'subsample':        Real(0.5, 0.9),\n",
    "             'colsample_bytree': Real(0.7, 1.0),\n",
    "             'min_child_weight': Real(1.0e-3, 1.0e-1, prior='log-uniform'),\n",
    "             'reg_alpha':        Real(1.0e-5, 1.0e1, prior='log-uniform'),\n",
    "             'reg_lambda':       Real(1.0e-5, 1.0e1, prior='log-uniform')\n",
    "            }\n",
    "estimator = BayesSearchCV(LGBMRegressor(boosting_type='gbdt',\n",
    "                                        objective='regression',\n",
    "                                        subsample_freq=1,\n",
    "                                        n_jobs=-1,\n",
    "                                        importance_type='gain'\n",
    "                                       ),\n",
    "                          spaces,\n",
    "                          n_iter=100,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          n_jobs=-1,\n",
    "                          cv=cv,\n",
    "                          random_state=RAND\n",
    "                         )         \n",
    "\n",
    "# fit the estimator\n",
    "t = time.time()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "t = time.time() - t\n",
    "print(f'Optimisation time: {t:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_estimator, cv_score, best_hyperparameters = statisticsCV(estimator, cv)\n",
    "print(f'CV score: {-cv_score[0]:.3f} ± {cv_score[1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save best estimator\n",
    "joblib.dump(best_estimator, pmod(PREFIX + 'gbdt' + SUFFIX + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the hyperparameters\n",
    "best_hyperparameters.to_csv(pmet(PREFIX + 'gbdt_hyperparameters' + SUFFIX + '.csv'))\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_metrics = make_predictions(best_estimator, X_train, y_train, last_train, prefix=PREFIX, suffix=SUFFIX, name='train_gbdt')\n",
    "test_metrics  = make_predictions(best_estimator, X_test, y_test, last_test, prefix=PREFIX, suffix=SUFFIX, name='test_gbdt')\n",
    "\n",
    "# concatenate the prediction results\n",
    "metrics = pd.concat([train_metrics, test_metrics], axis=0).transpose()\n",
    "metrics.to_csv(pmet(PREFIX + 'gbdt_metrics' + SUFFIX + '.csv'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_plots(estimator, X_train, y_train, last_train, prefix=PREFIX, suffix=SUFFIX, name='train_gbdt')\n",
    "make_plots(estimator, X_test, y_test, last_test, prefix=PREFIX, suffix=SUFFIX, name='test_gbdt')\n",
    "compare_plots(estimator, X_train, y_train, last_train, X_test, y_test, last_test, legend=['training', 'test'], prefix=PREFIX, suffix=SUFFIX, name='gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'gbdt_residual_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'gbdt_ratio_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'gbdt_residual_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'gbdt_ratio_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Artificial Neural Network (w/ Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "ann = keras.models.Sequential([keras.layers.Input(shape=X_train_nn.shape[1:], name='input'),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(50,\n",
    "                                                  #kernel_regularizer=keras.regularizers.l2(1.0e-5),\n",
    "                                                 ),\n",
    "                               keras.layers.LeakyReLU(0.05),\n",
    "                               keras.layers.Dropout(0.03),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(30,\n",
    "                                                  #kernel_regularizer=keras.regularizers.l2(1.0e-5),\n",
    "                                                 ),\n",
    "                               keras.layers.LeakyReLU(0.05),\n",
    "                               keras.layers.Dropout(0.05),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(20,\n",
    "                                                  #kernel_regularizer=keras.regularizers.l2(1.0e-5),\n",
    "                                                 ),\n",
    "                               keras.layers.LeakyReLU(0.05),\n",
    "                               keras.layers.Dropout(0.05),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(20,\n",
    "                                                  #kernel_regularizer=keras.regularizers.l2(1.0e-5),\n",
    "                                                 ),\n",
    "                               keras.layers.LeakyReLU(0.05),\n",
    "                               keras.layers.Dropout(0.05),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(10,\n",
    "                                                  #kernel_regularizer=keras.regularizers.l2(1.0e-5),\n",
    "                                                 ),\n",
    "                               keras.layers.LeakyReLU(0.05),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(10,\n",
    "                                                  #kernel_regularizer=keras.regularizers.l2(1.0e-5),\n",
    "                                                 ),\n",
    "                               keras.layers.LeakyReLU(0.05),\n",
    "                               #####################################################################\n",
    "                               keras.layers.Dense(1, name='exp')\n",
    "                              ],\n",
    "                              name='wzw'\n",
    "                             )\n",
    "ann.compile(optimizer=keras.optimizers.Adam(learning_rate=1.0e-3),\n",
    "            loss=keras.losses.MeanSquaredError(),\n",
    "            metrics=[keras.metrics.MeanSquaredError(), keras.metrics.MeanAbsoluteError()]\n",
    "           )\n",
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save figure\n",
    "ann_dot = keras.utils.model_to_dot(ann,\n",
    "                                   #rankdir='LR',\n",
    "                                   rankdir='TB',\n",
    "                                   show_shapes=True,\n",
    "                                   dpi=150)\n",
    "ann_dot.write_pdf(pimg(PREFIX + 'ann_arch' + SUFFIX + '.pdf'))\n",
    "Image(ann_dot.create_png(), width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    '''\n",
    "    Schedule the learning rate:\n",
    "    \n",
    "    Arguments:\n",
    "        epoch: the current epoch,\n",
    "        lr:    the current learning rate.\n",
    "    '''\n",
    "    if epoch < 1000:\n",
    "        return lr\n",
    "    else:\n",
    "        if lr <= 1.0e-6:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "ann_history = ann.fit(x=X_train_nn,\n",
    "                      y=y_train_nn,\n",
    "                      batch_size=32,\n",
    "                      epochs=20000,\n",
    "                      verbose=0,\n",
    "                      callbacks=[keras.callbacks.EarlyStopping(patience=2500, restore_best_weights=True, verbose=0),\n",
    "                                 keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=0),\n",
    "                                 keras.callbacks.ModelCheckpoint(pmod(PREFIX + 'ann' + SUFFIX + '.h5'), verbose=0, save_best_only=True)\n",
    "                                ],\n",
    "                      validation_data=(X_val_nn, y_val_nn)\n",
    "                     )\n",
    "t = time.time() - t\n",
    "print(f'Training took {t:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save and display history\n",
    "ann_history_obj = pd.DataFrame(ann_history.history)\n",
    "ann_history_obj.to_csv(pmod(PREFIX + 'ann_history' + SUFFIX + '.csv'), index=False)\n",
    "print(f'No. of epochs: {ann_history_obj.shape[0]:d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_plots(ann_history_obj, prefix=PREFIX, suffix=SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'ann_loss' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'ann_lr' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_metrics = make_predictions(ann, X_train_nn, y_train_nn, last_train_nn, prefix=PREFIX, suffix=SUFFIX, name='train_ann', tensor=True)\n",
    "val_metrics   = make_predictions(ann, X_val_nn, y_val_nn, last_val_nn, prefix=PREFIX, suffix=SUFFIX, name='val_ann', tensor=True)\n",
    "test_metrics  = make_predictions(ann, X_test_nn, y_test_nn, last_test_nn, prefix=PREFIX, suffix=SUFFIX, name='test_ann', tensor=True)\n",
    "\n",
    "# concatenate the prediction results\n",
    "metrics = pd.concat([train_metrics, val_metrics, test_metrics], axis=0).transpose()\n",
    "metrics.to_csv(pmet(PREFIX + 'ann_metrics' + SUFFIX + '.csv'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_plots(ann, X_train_nn, y_train_nn, last_train_nn, prefix=PREFIX, suffix=SUFFIX, name='train_ann')\n",
    "make_plots(ann, X_val_nn, y_val_nn, last_val_nn, prefix=PREFIX, suffix=SUFFIX, name='val_ann')\n",
    "make_plots(ann, X_test_nn, y_test_nn, last_test_nn, prefix=PREFIX, suffix=SUFFIX, name='test_ann')\n",
    "compare_plots_val(ann,\n",
    "                  X_train_nn, y_train_nn, last_train_nn,\n",
    "                  X_val_nn, y_val_nn, last_val_nn,\n",
    "                  X_test_nn, y_test_nn, last_test_nn,\n",
    "                  legend=['training', 'validation', 'test'],\n",
    "                  prefix=PREFIX,\n",
    "                  suffix=SUFFIX,\n",
    "                  name='ann'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'ann_residual_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'ann_ratio_histogram_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'ann_residual_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(pimg(PREFIX + 'ann_ratio_scatterplot_compare' + SUFFIX + '.png'), width=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "duration": 91.939387,
   "end_time": "2020-08-30T01:20:10.513504",
   "environment_variables": {},
   "exception": true,
   "input_path": "./wzw_ml_angle_weight0.ipynb",
   "output_path": "wzw_ml_angle_weight0_output.ipynb",
   "parameters": {},
   "start_time": "2020-08-30T01:18:38.574117",
   "version": "2.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}